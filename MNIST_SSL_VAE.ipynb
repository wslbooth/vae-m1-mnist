{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM0IzrDsgY7vTcyiYiZ60ho",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wslbooth/vae-m1-mnist/blob/main/MNIST_SSL_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Latent Feature Extraction (M1) on MNIST Dataset\n",
        "\n",
        "The goal of this project is to implement the latent feature extraction with a classifier (M1) from [1], and see if we can acheive similar results."
      ],
      "metadata": {
        "id": "B7gcRNgYbQFL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Section 1: Setup"
      ],
      "metadata": {
        "id": "Rp41R09abgyd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tn2eJG7NGo6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_fn(y_true, y_pred):\n",
        "  y_pred_classes = y_pred.argmax(dim=1)\n",
        "  correct = torch.eq(y_true, y_pred_classes).sum().item()\n",
        "  acc = (correct/len(y_pred))*100\n",
        "  return acc"
      ],
      "metadata": {
        "id": "ZilMQ_-fYkmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 22\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)"
      ],
      "metadata": {
        "id": "XyOmGVN5ZSUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "QAWR9Q_tVywa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor(),\n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor(),\n",
        "    target_transform=None\n",
        ")"
      ],
      "metadata": {
        "id": "NdJf2OnrV7s_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "l_size = int(0.01 * len(train_data))\n",
        "u_size = len(train_data) - l_size\n",
        "l_data, u_data = random_split(train_data, [l_size,u_size])\n",
        "\n",
        "batch_size = 32\n",
        "l_data_loader = DataLoader(dataset=l_data,\n",
        "                           batch_size=batch_size,\n",
        "                           shuffle=True)\n",
        "train_loader = DataLoader(dataset=train_data,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_data,\n",
        "                         batch_size=100)"
      ],
      "metadata": {
        "id": "2mx__K6oWX8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "l_data_labels = [int(train_data.targets[i]) for i in l_data.indices]\n",
        "l_data_class_counts = Counter(l_data_labels)\n",
        "l_data_class_counts"
      ],
      "metadata": {
        "id": "DpnHzuQaXa_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Section 2: Creating Model Classes\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0oyYYQpqb7ob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self,\n",
        "               in_dim,\n",
        "               hid_dim,\n",
        "               out_dim):\n",
        "    super().__init__()\n",
        "    self.layer_stack = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_dim,hid_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hid_dim,out_dim)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layer_stack(x)"
      ],
      "metadata": {
        "id": "PuufBMHkXxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, in_dim, hid_dim, latent_dim):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(in_dim, hid_dim)\n",
        "    self.fc_mu = nn.Linear(hid_dim, latent_dim)\n",
        "    self.fc_logvar = nn.Linear(hid_dim, latent_dim)\n",
        "\n",
        "  def forward(self,x):\n",
        "    h = F.softplus(self.fc1(x))\n",
        "    return self.fc_mu(h), self.fc_logvar(h)\n",
        "\n",
        "def reparameterize(mu, logvar):\n",
        "  std = torch.exp(0.5*logvar)\n",
        "  eps = torch.randn_like(std)\n",
        "  return mu + eps * std\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, latent_dim, hid_dim, out_dim):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(latent_dim, hid_dim),\n",
        "        nn.Softplus(),\n",
        "        nn.Linear(hid_dim, out_dim),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self, z):\n",
        "    return self.net(z)\n",
        "\n",
        "class VAE(nn.Module):\n",
        "  def __init__(self, in_dim, hid_dim, latent_dim, out_dim):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(in_dim, hid_dim, latent_dim)\n",
        "    self.decoder = Decoder(latent_dim, hid_dim, out_dim)\n",
        "\n",
        "  def forward(self,x):\n",
        "    mu, logvar = self.encoder(x)\n",
        "    z = reparameterize(mu, logvar)\n",
        "    x_hat = self.decoder(z)\n",
        "    return x_hat, mu, logvar"
      ],
      "metadata": {
        "id": "fwdspBlhYhww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderClassifier(nn.Module):\n",
        "  def __init__(self, encoder, mlp):\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.mlp = mlp\n",
        "\n",
        "    for param in self.encoder.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = torch.flatten(x,start_dim=1)\n",
        "    mu, logvar = self.encoder(x)\n",
        "    return self.mlp(mu)"
      ],
      "metadata": {
        "id": "QYvTuz1tcQwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Section 3: Model Training and Results"
      ],
      "metadata": {
        "id": "4-Myqgxxcd6L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.1 Baseline Model Training"
      ],
      "metadata": {
        "id": "3lBFP7bWc1N6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "m0 = MLP(\n",
        "    in_dim=784,\n",
        "    hid_dim=64,\n",
        "    out_dim=10\n",
        ").to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=m0.parameters(),lr=0.1)\n",
        "\n",
        "avg_loss_vals = []\n",
        "train_acc_vals = []\n",
        "test_acc_vals = []\n",
        "\n",
        "epochs = 50\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  m0.train()\n",
        "  train_loss = 0\n",
        "  train_acc = 0\n",
        "  for batch, (X,y) in enumerate(l_data_loader):\n",
        "    X,y = X.to(device),y.to(device)\n",
        "    y_pred = m0(X)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    acc = accuracy_fn(y, y_pred)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss += loss.item()\n",
        "    train_acc += acc\n",
        "  avg_loss = train_loss / len(l_data_loader)\n",
        "  avg_loss_vals.append(avg_loss)\n",
        "  avg_train_acc = train_acc / len(l_data_loader)\n",
        "  train_acc_vals.append(avg_train_acc)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    test_acc = 0\n",
        "    for X,y in test_loader:\n",
        "      X,y = X.to(device),y.to(device)\n",
        "      preds = m0(X)\n",
        "      test_acc += accuracy_fn(y, preds)\n",
        "  test_acc_vals.append(test_acc/len(test_loader))"
      ],
      "metadata": {
        "id": "c8ZlBVHbdBvD",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Baseline Model Results"
      ],
      "metadata": {
        "id": "tGe5imNq3kKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(avg_loss_vals)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Training Loss\")\n",
        "plt.figure()\n",
        "plt.plot(train_acc_vals)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Training Accuracy (%)\")\n",
        "plt.figure()\n",
        "plt.plot(test_acc_vals)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Testing Accuracy (%)\")"
      ],
      "metadata": {
        "id": "iObR6KpTjIxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_acc_vals)\n",
        "print(test_acc_vals)\n",
        "print(f\"Max Training Accuracy of {max(train_acc_vals)} after Epoch {np.argmax(train_acc_vals)+1}\")\n",
        "print(f\"Max Test Accuracy of {max(test_acc_vals)} after Epoch {np.argmax(test_acc_vals)+1}\")\n",
        "num_params = sum(p.numel() for p in m0.parameters() if p.requires_grad)\n",
        "print(num_params)"
      ],
      "metadata": {
        "id": "OT6x2M52NMoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2 VAE Training"
      ],
      "metadata": {
        "id": "_1ooeS5LdC4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vae_loss(x, x_hat, mu, logvar, beta=1.0):\n",
        "  recon_loss = F.mse_loss(x_hat, x, reduction='sum')\n",
        "  kld = -0.5 * torch.sum(1+logvar - mu.pow(2) - logvar.exp())\n",
        "  return recon_loss + beta * kld, recon_loss.item(), kld.item()\n",
        "\n",
        "model_vae = VAE(\n",
        "    in_dim=784,\n",
        "    hid_dim=400,\n",
        "    latent_dim=100,\n",
        "    out_dim=784\n",
        ").to(device)\n",
        "\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "optimizer = torch.optim.Adam(model_vae.parameters(), lr=0.001)\n",
        "schedular = ExponentialLR(optimizer, gamma=0.99)"
      ],
      "metadata": {
        "id": "YXYcrIEwlt8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "\n",
        "loss_vals = []\n",
        "kld_vals = []\n",
        "recon_loss_vals = []\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  model_vae.train()\n",
        "  total_loss = 0\n",
        "  total_kld = 0\n",
        "  total_recon_loss = 0\n",
        "  for batch, _ in train_loader:\n",
        "    batch = batch.view(-1, 784)\n",
        "    batch = batch.to(device)\n",
        "\n",
        "    x_hat, mu, logvar = model_vae(batch)\n",
        "    loss, recon_loss, kld = vae_loss(batch, x_hat, mu, logvar)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    total_kld += kld\n",
        "    total_recon_loss += recon_loss\n",
        "  schedular.step()\n",
        "  avg_loss = total_loss / len(train_loader.dataset)\n",
        "  loss_vals.append(avg_loss)\n",
        "  avg_kld = total_kld / len(train_loader.dataset)\n",
        "  kld_vals.append(avg_kld)\n",
        "  avg_recon_loss = total_recon_loss / len(train_loader.dataset)\n",
        "  recon_loss_vals.append(avg_recon_loss)\n",
        "  #print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}, KLdivergence: {avg_kld}, Recon Loss: {avg_recon_loss}\")\n"
      ],
      "metadata": {
        "id": "xa92H2X3ntaj",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(loss_vals)\n",
        "plt.xlabel(\"Training Loss\")\n",
        "plt.ylabel(\"Epoch\")\n",
        "plt.figure()\n",
        "plt.plot(kld_vals)\n",
        "plt.xlabel(\"KL-Divergence\")\n",
        "plt.ylabel(\"Epoch\")\n",
        "plt.figure()\n",
        "plt.xlabel(\"Reconstruction Loss (MSE)\")\n",
        "plt.ylabel(\"Epoch\")\n",
        "plt.plot(recon_loss_vals)"
      ],
      "metadata": {
        "id": "UsYqDF7lUQTF",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.3 M1 Training"
      ],
      "metadata": {
        "id": "bx3VULmDdcbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = MLP(in_dim=100, hid_dim=64, out_dim=10)\n",
        "\n",
        "m1 = EncoderClassifier(encoder=model_vae.encoder,\n",
        "                       mlp=mlp).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=m1.parameters(), lr=0.1)\n",
        "\n",
        "avg_loss_vals = []\n",
        "train_acc_vals = []\n",
        "test_acc_vals = []\n",
        "\n",
        "epochs = 50\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  m1.train()\n",
        "  train_loss = 0\n",
        "  train_acc = 0\n",
        "  for batch, (X,y) in enumerate(l_data_loader):\n",
        "    X,y = X.to(device),y.to(device)\n",
        "    y_pred = m1(X)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    acc = accuracy_fn(y, y_pred)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss += loss.item()\n",
        "    train_acc += acc\n",
        "  avg_loss = train_loss / len(l_data_loader)\n",
        "  avg_loss_vals.append(avg_loss)\n",
        "  avg_train_acc = train_acc / len(l_data_loader)\n",
        "  train_acc_vals.append(avg_train_acc)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    test_acc = 0\n",
        "    for X,y in test_loader:\n",
        "      X,y = X.to(device),y.to(device)\n",
        "      preds = m1(X)\n",
        "      test_acc += accuracy_fn(y, preds)\n",
        "  test_acc_vals.append(test_acc/len(test_loader))"
      ],
      "metadata": {
        "id": "qWDdyvE8tXS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####M1 Results"
      ],
      "metadata": {
        "id": "p7uhDASyeew7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(avg_loss_vals)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Training Loss\")\n",
        "plt.figure()\n",
        "plt.plot(train_acc_vals)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Training Accuracy (%)\")\n",
        "plt.figure()\n",
        "plt.plot(test_acc_vals)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Test Accuracy (%)\")"
      ],
      "metadata": {
        "id": "Rf1V1mchuO0e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_acc_vals)\n",
        "print(test_acc_vals)\n",
        "print(f\"Max Training Accuracy of {max(train_acc_vals)} after Epoch {np.argmax(train_acc_vals)+1}\")\n",
        "print(f\"Max Test Accuracy of {max(test_acc_vals)} after Epoch {np.argmax(test_acc_vals)+1}\")\n",
        "num_params = sum(p.numel() for p in m0.parameters() if p.requires_grad)\n",
        "print(num_params)"
      ],
      "metadata": {
        "id": "dd5H89tsOJNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Discussion of Results\n",
        "\n",
        "As we have seen, our classifier with the latent feature extractor beats our baseline model. After training each model for 50 epochs, the baseline model achieved a max test accuracy of 86.21% after epoch 41, and our M1 achieved a max test accuracy of 88.8%, after epoch 49.\n",
        "\n",
        "Therefore, we can conclude that the latent feature extraction performed by the encoder, does increase the ability of the classifier to generalize to unseen data. So, our VAE is learning useful discriminitive latent features."
      ],
      "metadata": {
        "id": "AXRzo62B8RMZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##References:\n",
        "[1] Kingma, D. P., Rezende, D. J., Mohamed, S., & Welling, M. (2014).  \n",
        "Semi-Supervised Learning with Deep Generative Models.  \n",
        "_NeurIPS 27_.  \n",
        "https://arxiv.org/abs/1406.5298\n",
        "\n",
        "[2]Doersch, C. (2016).\n",
        "Tutorial on Variational Autoencoders.\n",
        "arXiv preprint arXiv:1606.05908.\n",
        "https://arxiv.org/abs/1606.05908\n",
        "\n",
        "[3]Kingma, D. P., & Welling, M. (2014).\n",
        "Auto-Encoding Variational Bayes.\n",
        "arXiv preprint arXiv:1312.6114.\n",
        "https://arxiv.org/abs/1312.6114"
      ],
      "metadata": {
        "id": "UDVmj6Sd5Nma"
      }
    }
  ]
}